{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from tools import (\n",
    "    load_embeddings_and_labels, \n",
    "    train_music_model, \n",
    "    evaluate,\n",
    "    id_to_labels,\n",
    "    logits_to_probs,\n",
    "    logits_to_text    \n",
    ")\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "{'cls': {'target_of_toy_ad': 1.0,\n",
      "         'voice_age': 0.7912087912087912,\n",
      "         'voice_gender': 0.6031746031746031},\n",
      " 'emo': {'Angry': 0.6714285714285715,\n",
      "         'Beauty': 0.8507936507936508,\n",
      "         'Calm': 0.7023809523809523,\n",
      "         'Happy': 0.7023809523809523},\n",
      " 'mid': {'Dense/Sparse': 0.8507936507936508,\n",
      "         'Distorted/Clear': 0.4047619047619047,\n",
      "         'Electric/Acoustic': 0.7142857142857143,\n",
      "         'Harmonious/Disharmonious': 0.42857142857142855,\n",
      "         'Heavy/Light': 0.8507936507936508,\n",
      "         'High pitch/Low pitch': 0.7023809523809523,\n",
      "         'Loud/Soft': 0.8507936507936508,\n",
      "         'Punchy/Smooth': 0.7142857142857143,\n",
      "         'Strong beat/Weak beat': 0.8634920634920634}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "{'cls': {'target_of_toy_ad': 0.5, 'voice_age': 1.0, 'voice_gender': 1.0},\n",
      " 'emo': {'Angry': 0.7023809523809523,\n",
      "         'Beauty': 0.8634920634920634,\n",
      "         'Calm': 0.5142857142857143,\n",
      "         'Happy': 0.8507936507936508},\n",
      " 'mid': {'Dense/Sparse': 0.8571428571428571,\n",
      "         'Distorted/Clear': 0.7023809523809523,\n",
      "         'Electric/Acoustic': 0.6233766233766234,\n",
      "         'Harmonious/Disharmonious': 0.34285714285714286,\n",
      "         'Heavy/Light': 0.7023809523809523,\n",
      "         'High pitch/Low pitch': 0.6714285714285715,\n",
      "         'Loud/Soft': 1.0,\n",
      "         'Punchy/Smooth': 0.8507936507936508,\n",
      "         'Strong beat/Weak beat': 0.7142857142857143}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3\n",
      "{'cls': {'target_of_toy_ad': 0.8707482993197279,\n",
      "         'voice_age': 0.4155844155844156,\n",
      "         'voice_gender': 0.8507936507936508},\n",
      " 'emo': {'Angry': 0.7142857142857143,\n",
      "         'Beauty': 0.8507936507936508,\n",
      "         'Calm': 0.5523809523809524,\n",
      "         'Happy': 1.0},\n",
      " 'mid': {'Dense/Sparse': 0.7142857142857143,\n",
      "         'Distorted/Clear': 0.8507936507936508,\n",
      "         'Electric/Acoustic': 0.7023809523809523,\n",
      "         'Harmonious/Disharmonious': 0.7142857142857143,\n",
      "         'Heavy/Light': 1.0,\n",
      "         'High pitch/Low pitch': 1.0,\n",
      "         'Loud/Soft': 1.0,\n",
      "         'Punchy/Smooth': 0.8507936507936508,\n",
      "         'Strong beat/Weak beat': 1.0}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4\n",
      "{'cls': {'target_of_toy_ad': 0.7222222222222222,\n",
      "         'voice_age': 0.7912087912087912,\n",
      "         'voice_gender': 0.4408163265306122},\n",
      " 'emo': {'Angry': 0.6,\n",
      "         'Beauty': 0.5523809523809524,\n",
      "         'Calm': 0.4523809523809524,\n",
      "         'Happy': 0.25396825396825395},\n",
      " 'mid': {'Dense/Sparse': 0.7142857142857143,\n",
      "         'Distorted/Clear': 0.7142857142857143,\n",
      "         'Electric/Acoustic': 0.8571428571428571,\n",
      "         'Harmonious/Disharmonious': 0.5904761904761904,\n",
      "         'Heavy/Light': 0.8507936507936508,\n",
      "         'High pitch/Low pitch': 0.5523809523809524,\n",
      "         'Loud/Soft': 0.7261904761904762,\n",
      "         'Punchy/Smooth': 0.7023809523809523,\n",
      "         'Strong beat/Weak beat': 1.0}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5\n",
      "{'cls': {'target_of_toy_ad': 0.7142857142857143,\n",
      "         'voice_age': 0.5952380952380952,\n",
      "         'voice_gender': 1.0},\n",
      " 'emo': {'Angry': 0.8634920634920634,\n",
      "         'Beauty': 0.25396825396825395,\n",
      "         'Calm': 0.7272727272727273,\n",
      "         'Happy': 0.7261904761904762},\n",
      " 'mid': {'Dense/Sparse': 0.8571428571428571,\n",
      "         'Distorted/Clear': 0.7261904761904762,\n",
      "         'Electric/Acoustic': 0.8744588744588745,\n",
      "         'Harmonious/Disharmonious': 0.7142857142857143,\n",
      "         'Heavy/Light': 0.8634920634920634,\n",
      "         'High pitch/Low pitch': 0.7142857142857143,\n",
      "         'Loud/Soft': 0.7261904761904762,\n",
      "         'Punchy/Smooth': 0.5714285714285714,\n",
      "         'Strong beat/Weak beat': 0.8634920634920634}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6\n",
      "{'cls': {'target_of_toy_ad': 0.6944444444444443,\n",
      "         'voice_age': 0.5952380952380952,\n",
      "         'voice_gender': 0.6493506493506492},\n",
      " 'emo': {'Angry': 0.8398268398268397,\n",
      "         'Beauty': 0.6714285714285715,\n",
      "         'Calm': 0.8398268398268397,\n",
      "         'Happy': 0.8398268398268397},\n",
      " 'mid': {'Dense/Sparse': 0.7023809523809523,\n",
      "         'Distorted/Clear': 0.7142857142857143,\n",
      "         'Electric/Acoustic': 0.7571428571428572,\n",
      "         'Harmonious/Disharmonious': 0.9230769230769231,\n",
      "         'Heavy/Light': 0.6714285714285715,\n",
      "         'High pitch/Low pitch': 0.5523809523809524,\n",
      "         'Loud/Soft': 0.7023809523809523,\n",
      "         'Punchy/Smooth': 0.38095238095238093,\n",
      "         'Strong beat/Weak beat': 0.38095238095238093}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7\n",
      "{'cls': {'target_of_toy_ad': 1.0,\n",
      "         'voice_age': 0.5333333333333333,\n",
      "         'voice_gender': 0.7666666666666666},\n",
      " 'emo': {'Angry': 0.5142857142857142,\n",
      "         'Beauty': 0.625,\n",
      "         'Calm': 0.6666666666666666,\n",
      "         'Happy': 0.8380952380952381},\n",
      " 'mid': {'Dense/Sparse': 0.6666666666666666,\n",
      "         'Distorted/Clear': 0.6666666666666666,\n",
      "         'Electric/Acoustic': 0.5333333333333333,\n",
      "         'Harmonious/Disharmonious': 0.45714285714285713,\n",
      "         'Heavy/Light': 0.6666666666666666,\n",
      "         'High pitch/Low pitch': 0.8380952380952381,\n",
      "         'Loud/Soft': 0.6666666666666666,\n",
      "         'Punchy/Smooth': 0.8148148148148148,\n",
      "         'Strong beat/Weak beat': 0.7575757575757575}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8\n",
      "{'cls': {'target_of_toy_ad': 0.0, 'voice_age': 1.0, 'voice_gender': 1.0},\n",
      " 'emo': {'Angry': 0.8285714285714286,\n",
      "         'Beauty': 0.8380952380952381,\n",
      "         'Calm': 0.851851851851852,\n",
      "         'Happy': 0.09523809523809523},\n",
      " 'mid': {'Dense/Sparse': 0.5142857142857142,\n",
      "         'Distorted/Clear': 0.6666666666666666,\n",
      "         'Electric/Acoustic': 0.8285714285714286,\n",
      "         'Harmonious/Disharmonious': 0.8285714285714286,\n",
      "         'Heavy/Light': 0.8148148148148148,\n",
      "         'High pitch/Low pitch': 0.8285714285714286,\n",
      "         'Loud/Soft': 0.8285714285714286,\n",
      "         'Punchy/Smooth': 1.0,\n",
      "         'Strong beat/Weak beat': 0.8285714285714286}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9\n",
      "{'cls': {'target_of_toy_ad': 0.5,\n",
      "         'voice_age': 0.5333333333333333,\n",
      "         'voice_gender': 0.6547619047619048},\n",
      " 'emo': {'Angry': 0.6666666666666666,\n",
      "         'Beauty': 0.8380952380952381,\n",
      "         'Calm': 0.5428571428571428,\n",
      "         'Happy': 0.4166666666666667},\n",
      " 'mid': {'Dense/Sparse': 1.0,\n",
      "         'Distorted/Clear': 0.851851851851852,\n",
      "         'Electric/Acoustic': 0.7083333333333334,\n",
      "         'Harmonious/Disharmonious': 0.48571428571428577,\n",
      "         'Heavy/Light': 1.0,\n",
      "         'High pitch/Low pitch': 0.8285714285714286,\n",
      "         'Loud/Soft': 1.0,\n",
      "         'Punchy/Smooth': 1.0,\n",
      "         'Strong beat/Weak beat': 0.25}}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10\n",
      "{'cls': {'target_of_toy_ad': 0.6666666666666666,\n",
      "         'voice_age': 0.3333333333333333,\n",
      "         'voice_gender': 0.39999999999999997},\n",
      " 'emo': {'Angry': 0.6666666666666666,\n",
      "         'Beauty': 0.6666666666666666,\n",
      "         'Calm': 0.5142857142857142,\n",
      "         'Happy': 0.6666666666666666},\n",
      " 'mid': {'Dense/Sparse': 0.8285714285714286,\n",
      "         'Distorted/Clear': 1.0,\n",
      "         'Electric/Acoustic': 0.8380952380952381,\n",
      "         'Harmonious/Disharmonious': 1.0,\n",
      "         'Heavy/Light': 0.8285714285714286,\n",
      "         'High pitch/Low pitch': 1.0,\n",
      "         'Loud/Soft': 0.8285714285714286,\n",
      "         'Punchy/Smooth': 0.5142857142857142,\n",
      "         'Strong beat/Weak beat': 0.3333333333333333}}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/homes/lm004/toys-critical-analysis\")\n",
    "#test_original_ids = [] # placeholder, in cv_by_graph.py this is replaced by the actual test set\n",
    "\n",
    "with open('music/config_binary_training.yaml', 'r') as f:\n",
    "    music_config_training = yaml.safe_load(f)\n",
    "\n",
    "music_df = pd.read_csv('music/music_binary_groundtruth.csv', index_col=\"stimulus_id\")\n",
    "# remove test set from the data\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "results = []\n",
    "for fold_idx, (train_index, test_index) in enumerate(kf.split(music_df)):\n",
    "\n",
    "    X, y_mid, y_emo, y_cls = load_embeddings_and_labels(\n",
    "        music_df.iloc[test_index], \n",
    "        music_config_training['mid_dict'],\n",
    "        music_config_training['emo_dict'],\n",
    "        music_config_training['cls_dict']\n",
    "    )\n",
    "    #X.shape[0], y_mid[\"Electric/Acoustic\"].shape[0], y_emo[\"Happy\"].shape[0], y_cls[\"target_of_toy_ad\"].shape[0]\n",
    "\n",
    "    music_train_index, music_test_index = train_test_split(range(X.shape[0]), test_size=0.10, random_state=42)\n",
    "\n",
    "\n",
    "    X_train = X[music_train_index]\n",
    "    X_test = X[music_test_index]\n",
    "    y_mid_train = {k: v[music_train_index] for k, v in y_mid.items()}\n",
    "    y_mid_test = {k: v[music_test_index] for k, v in y_mid.items()}\n",
    "    y_emo_train = {k: v[music_train_index] for k, v in y_emo.items()}\n",
    "    y_emo_test = {k: v[music_test_index] for k, v in y_emo.items()}\n",
    "    y_cls_train = {k: v[music_train_index] for k, v in y_cls.items()}\n",
    "    y_cls_test = {k: v[music_test_index] for k, v in y_cls.items()}\n",
    "\n",
    "    music_model = train_music_model(\n",
    "        music_config_training, X_train, y_mid_train, y_emo_train, y_cls_train\n",
    "    )\n",
    "\n",
    "    results.append(evaluate(music_model, music_config_training, X_test, y_mid_test, y_emo_test, y_cls_test))\n",
    "\n",
    "    print(f\"Fold {fold_idx+1}\")\n",
    "    pprint(results[-1])\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls target_of_toy_ad = 0.67 +/- 0.28\n",
      "cls voice_age = 0.66 +/- 0.22\n",
      "cls voice_gender = 0.74 +/- 0.21\n",
      "cls average = 0.69 +/- 0.03\n",
      "mid Strong beat/Weak beat = 0.70 +/- 0.26\n",
      "mid Electric/Acoustic = 0.74 +/- 0.10\n",
      "mid Distorted/Clear = 0.73 +/- 0.15\n",
      "mid Loud/Soft = 0.83 +/- 0.12\n",
      "mid Heavy/Light = 0.82 +/- 0.11\n",
      "mid High pitch/Low pitch = 0.77 +/- 0.15\n",
      "mid Punchy/Smooth = 0.74 +/- 0.19\n",
      "mid Harmonious/Disharmonious = 0.65 +/- 0.21\n",
      "mid Dense/Sparse = 0.77 +/- 0.13\n",
      "mid average = 0.75 +/- 0.05\n",
      "emo Happy = 0.64 +/- 0.28\n",
      "emo Beauty = 0.70 +/- 0.18\n",
      "emo Calm = 0.64 +/- 0.13\n",
      "emo Angry = 0.71 +/- 0.10\n",
      "emo average = 0.67 +/- 0.03\n"
     ]
    }
   ],
   "source": [
    "for task in [\"cls\", \"mid\", \"emo\"]:\n",
    "    task_averages = []\n",
    "    for subtask in music_config_training[f\"{task}_dict\"].keys():\n",
    "        main_results = [rslt[task][subtask] for rslt in results]\n",
    "        print(f\"{task} {subtask} = {np.mean(main_results):.2f} +/- {np.std(main_results):.2f}\")\n",
    "        task_averages.append(np.mean(main_results))\n",
    "    print(f\"{task} average = {np.mean(task_averages):.2f} +/- {np.std(task_averages):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | batch_norm | BatchNorm1d | 2.0 K  | train\n",
      "1 | hidden     | Linear      | 524 K  | train\n",
      "2 | bn_mid     | BatchNorm1d | 1.0 K  | train\n",
      "3 | bn_emo     | BatchNorm1d | 1.0 K  | train\n",
      "4 | bn_cls     | BatchNorm1d | 1.0 K  | train\n",
      "5 | hidden_mid | Linear      | 131 K  | train\n",
      "6 | hidden_emo | Linear      | 131 K  | train\n",
      "7 | hidden_cls | Linear      | 131 K  | train\n",
      "8 | out        | ModuleDict  | 9.5 K  | train\n",
      "---------------------------------------------------\n",
      "933 K     Trainable params\n",
      "0         Non-trainable params\n",
      "933 K     Total params\n",
      "3.734     Total estimated model params size (MB)\n",
      "28        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=95` in the `DataLoader` to improve performance.\n",
      "/homes/lm004/.conda/envs/autocritical/lib/python3.13/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls target_of_toy_ad = 0.67\n",
      "cls voice_age = 0.77\n",
      "cls voice_gender = 0.83\n",
      "mid Strong beat/Weak beat = 0.73\n",
      "mid Electric/Acoustic = 0.76\n",
      "mid Distorted/Clear = 0.77\n",
      "mid Loud/Soft = 0.82\n",
      "mid Heavy/Light = 0.86\n",
      "mid High pitch/Low pitch = 0.75\n",
      "mid Punchy/Smooth = 0.71\n",
      "mid Harmonious/Disharmonious = 0.72\n",
      "mid Dense/Sparse = 0.82\n",
      "emo Happy = 0.70\n",
      "emo Beauty = 0.81\n",
      "emo Calm = 0.76\n",
      "emo Angry = 0.77\n"
     ]
    }
   ],
   "source": [
    "# retrain on all data (to compute the music descriptions)\n",
    "X, y_mid, y_emo, y_cls = load_embeddings_and_labels(\n",
    "    music_df,\n",
    "    music_config_training['mid_dict'],\n",
    "    music_config_training['emo_dict'],\n",
    "    music_config_training['cls_dict']\n",
    ")\n",
    "music_model, f1s_val = train_music_model(music_config_training, X, y_mid, y_emo, y_cls, return_metrics=True)\n",
    "\n",
    "# print validation metrics\n",
    "for task in [\"cls\", \"mid\", \"emo\"]:\n",
    "    for subtask in music_config_training[f\"{task}_dict\"].keys():\n",
    "        print(f\"{task} {subtask} = {f1s_val[task][subtask]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5d343e7c0c480387581945c397d542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2041 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unseen_datapoints_df = pd.read_csv(\n",
    "    \"files/unseen_transcripts.csv\", index_col=0\n",
    ")\n",
    "\n",
    "# run the model on all unseen datapoints\n",
    "for idx in tqdm(\n",
    "    unseen_datapoints_df.index, \n",
    "):    \n",
    "    # compute audio description for current datapoint\n",
    "    y_mid_label, y_emo_label, y_cls_label, y_logits = id_to_labels(\n",
    "        music_model, \n",
    "        music_config_training, # music_config_inference,\n",
    "        idx,\n",
    "        embeddings_dir=\"files/clap_embeddings\",\n",
    "    )\n",
    "\n",
    "    # save audio description to file\n",
    "    os.makedirs(\"results/complete_binary_music_predictions\", exist_ok=True)\n",
    "    with open(os.path.join(\"results/complete_binary_music_predictions\", f\"{idx}_music_pred.json\"), \"w\") as f:\n",
    "        json.dump({\"mid\": y_mid_label, \"emo\": y_emo_label, \"cls\": y_cls_label}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autocritical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
